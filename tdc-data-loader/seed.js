// seed.js
// ============================================================================
// Este script representa a **primeira etapa do pipeline de RAG**:
// aqui n√≥s criamos o "Data Lake" da aplica√ß√£o, carregando os dados brutos
// (palestras + informa√ß√µes do evento) dentro do MongoDB.
// ============================================================================

// Importamos o cliente nativo do MongoDB.
// Na narrativa da palestra, aqui voc√™ pode falar de:
// - "camada de dados corporativa"
// - "fonte √∫nica da verdade"
// - "Lake / Lakehouse onde o texto completo fica armazenado".
const { MongoClient } = require('mongodb');

// --------------------------------------------------------------------------
// Importa√ß√£o dos dados brutos
// --------------------------------------------------------------------------
// Esses arquivos JS simulam a "fonte oficial" de dados do TDC:
// poderiam ser um JSON vindo de uma API, um CSV, um HTML raspado, etc.
// Na pr√°tica, √© a **origem do conhecimento** que o RAG vai usar.
const talksDay1 = require('./data/talks_day1');
const talksDay2 = require('./data/talks_day2');
const eventInfo = require('./data/event_info');

// --------------------------------------------------------------------------
// Configura√ß√£o da conex√£o com o MongoDB
// --------------------------------------------------------------------------
// Aqui definimos a URI do MongoDB.
// - No ambiente local/Docker: usu√°rio/senha admin/admin.
// - authSource=admin indica onde as credenciais ser√£o validadas.
// Em PRO, isso seria uma connection string segura (Key Vault, vari√°vel de ambiente,
// managed identity, etc.).
const uri = "mongodb://admin:admin@localhost:27017/?authSource=admin";

// Criamos uma inst√¢ncia do cliente Mongo.
// Ele ainda N√ÉO est√° conectado; isso s√≥ acontece quando chamamos client.connect().
const client = new MongoClient(uri);

// --------------------------------------------------------------------------
// Fun√ß√£o principal de carga
// --------------------------------------------------------------------------
// Usamos uma fun√ß√£o async para:
// - conectar no banco,
// - limpar dados antigos,
// - inserir os novos documentos,
// - e fechar conex√£o no final.
// Isso simula um "job de ingest√£o" que poderia rodar em batch (cron, pipeline, etc.).
async function run() {
  try {
    console.log("üîå Conectando ao MongoDB...");
    // Abre a conex√£o f√≠sica com o servidor Mongo.
    // Aqui voc√™ pode comentar sobre pool de conex√µes, lat√™ncia, etc.
    await client.connect();
    
    // Escolhe (ou cria se n√£o existir) o database onde vamos trabalhar.
    // No contexto da palestra, esse DB √© o nosso "Data Lake l√≥gico".
    const db = client.db("tdc_data");
    console.log("‚úÖ Conectado ao banco 'tdc_data'");

    // ----------------------------------------------------------------------
    // 1. LIMPEZA (Reset do Data Lake)
    // ----------------------------------------------------------------------
    // Antes de uma nova sincroniza√ß√£o, limpamos as cole√ß√µes.
    // Isso demonstra o conceito de "reindexa√ß√£o" ou "full reload":
    // apagamos tudo e recarregamos a vers√£o mais atual da fonte oficial.
    console.log("üßπ Limpando cole√ß√µes antigas...");
    await db.collection("talks").deleteMany({});
    await db.collection("event_info").deleteMany({});

    // Aqui voc√™ pode explicar:
    // - Em produ√ß√£o, √†s vezes fazemos "upsert" em vez de apagar tudo.
    // - Mas para uma demo de RAG, √© did√°tico mostrar um full refresh.

    // ----------------------------------------------------------------------
    // 2. CONSOLIDA√á√ÉO DOS DADOS
    // ----------------------------------------------------------------------
    // Junta todas as atividades (palestras, keynotes, etc.) em um √∫nico array.
    // Isso √© o "conte√∫do bruto" que o modelo vai ler DEPOIS que o Qdrant
    // devolver os IDs.
    const allTalks = [...talksDay1, ...talksDay2];

    // ----------------------------------------------------------------------
    // 3. INSER√á√ÉO NO MONGODB (Data Lake)
    // ----------------------------------------------------------------------
    // Esse √© o ponto-chave da narrativa:
    // - Aqui n√≥s guardamos o **TEXTO COMPLETO** (t√≠tulo, descri√ß√£o, palestrante...)
    // - O MongoDB vira a **Fonte de Verdade**.
    // - O Qdrant N√ÉO armazena o texto completo, ele s√≥ guarda um √≠ndice vetorial
    //   que aponta para o _id desses documentos.
    console.log(`üöÄ Inserindo ${allTalks.length} palestras/atividades...`);

    // insertMany grava todas as palestras de uma vez.
    // O retorno traz, por exemplo, o n√∫mero de documentos inseridos.
    const talksResult = await db.collection("talks").insertMany(allTalks);

    console.log(`üìù ${talksResult.insertedCount} palestras inseridas.`);

    // Al√©m das talks, tamb√©m carregamos uma cole√ß√£o com as informa√ß√µes gerais
    // do evento (local, descri√ß√£o, pre√ßos, pol√≠ticas, etc).
    // Isso permite que o RAG responda perguntas do tipo:
    // - "Onde vai ser o TDC Porto Alegre?"
    // - "Quais s√£o os tipos de ingresso?"
    console.log("üöÄ Inserindo informa√ß√µes do evento...");
    await db.collection("event_info").insertOne(eventInfo);
    console.log("üìù Informa√ß√µes do evento inseridas.");

    console.log("‚ú® Carga de dados finalizada com sucesso!");
    // Aqui voc√™ pode fazer uma pausa e refor√ßar:
    // - "Neste momento, o nosso Data Lake est√° pronto."
    // - "Nada de vetor ainda. S√≥ dados brutos no Mongo."
    // - "O pr√≥ximo passo √© indexar isso em forma de embeddings no Qdrant."

  } catch (error) {
    // Bloco de tratamento de erro:
    // Qualquer problema de conex√£o/inser√ß√£o cai aqui.
    // Em produ√ß√£o, voc√™ poderia logar em um sistema centralizado (App Insights, Datadog, etc.).
    console.error("‚ùå Erro na carga de dados:", error);
  } finally {
    // O finally SEMPRE √© executado, com sucesso ou erro.
    // Fechar a conex√£o explicitamente √© uma boa pr√°tica em scripts one-shot.
    await client.close();
    console.log("üëã Conex√£o fechada.");
  }
}

// Chamamos a fun√ß√£o principal.
// Na palestra, isso te d√° gancho para falar de:
// - scripts de seed rodando em CI/CD,
// - jobs agendados (cron, Azure Functions Timer, etc.),
// - ou pipelines de ingest√£o (Data Factory / Synapse / Airflow).
run();
