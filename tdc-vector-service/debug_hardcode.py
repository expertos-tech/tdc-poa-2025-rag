import torch
import numpy as np
from langchain_huggingface import HuggingFaceEmbeddings
from numpy.linalg import norm

# 1. Configurar o mesmo modelo
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üñ•Ô∏è  Rodando teste em: {device.upper()}")

model = HuggingFaceEmbeddings(
    model_name="all-MiniLM-L6-v2",
    model_kwargs={'device': device}
)

# 2. Definir os textos exatos (Copiado do seu log)
query_text = "Rodrigo Tavares"
doc_text = (
    "ATIVIDADE: Construindo um RAG com seus Pr√≥prios Dados do Zero\n"
    "TIPO: TALK | TRILHA: IA Generativa e Dados\n"
    "PALESTRANTE: Rodrigo Tavares (Palestrante)\n"
    "DATA/HORA: Dia 2025-12-10 √†s 14:30\n"
    "RESUMO: Como montar um RAG com as suas informa√ß√µes do zero...\n"
    "LINKEDIN: https://www.linkedin.com/in/rgtavares/"
)

print("\nüßÆ Calculando vetores...")
vec_query = model.embed_query(query_text)
vec_doc = model.embed_query(doc_text) # Usamos embed_query para simular single text

# 3. C√°lculo manual de Cosine Similarity
# F√≥rmula: (A . B) / (||A|| * ||B||)
def cosine_similarity(v1, v2):
    return np.dot(v1, v2) / (norm(v1) * norm(v2))

score = cosine_similarity(vec_query, vec_doc)

print("-" * 40)
print(f"üó£Ô∏è  Query: '{query_text}'")
print(f"üìÑ  Doc: '...{doc_text[:50]}...'")
print("-" * 40)
print(f"üéØ SCORE DE SIMILARIDADE REAL (RAM): {score:.4f}")
print("-" * 40)

if score > 0.5:
    print("‚úÖ CONCLUS√ÉO: O Modelo funciona! O problema √© o upload para o Qdrant (Vetores corrompidos).")
else:
    print("‚ùå CONCLUS√ÉO: O Modelo acha que esses textos s√£o diferentes. O prompt/texto est√° confuso para ele.")